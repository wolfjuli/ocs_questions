\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{commath}

\graphicspath{{figures/}}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\T}[1]{#1^{\top}}
\newcommand{\kth}[2][k]{#2^{(#1)}}
\DeclareMathOperator{\diag}{diag}

\title{Summary of OCS Slides}
\author{Philipp Gabler}
\date{}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

\paragraph{General Form.} A general minimization problem has the form
\begin{equation*}
  \min_{x} f(x) \quad \text{s.t. } x \in X,
\end{equation*}
for a \emph{constraint set} \(X \subseteq \RR^n\) (often given by some \emph{constraint functions}
and an \emph{objective function} \(f: X \to \RR\).  We want to find an optimal value or
\emph{minimizer} \(x^* \in X\) such that
\begin{equation*}
  f(x^*) \leq f(x), \quad \forall x \in X.
\end{equation*}

\paragraph{Types of Optimization Problems.}
\begin{enumerate}
\item
  \begin{enumerate}
  \item Discrete: \(X\) is a discrete set, also called \emph{interger programming}.
  \item Continuous: \(X\) is continuous (ie. uncountable)
  \end{enumerate}
\item
  \begin{enumerate}
  \item Linear: Objective functions and constraints are all linear:
    \begin{equation*}
      \min_x \T{c} x, \quad\text{s.t. } Ax \leq b,\; x \geq 0.
    \end{equation*}
    Constraints describe a polyhedron.  Efficiently solvable.
  \item Quadratic: Objective function is quadratic, constraints linear:
    \begin{equation*}
      \min_x \frac{1}{2}\T{x} Q x + \T{c} x, \quad\text{s.t. } Ax \leq b,\; Ex = d.
    \end{equation*}
    If \(Q\) is positive semidefinite, the objective is convex and the problem is polynomially
    solvable.
  \item Nonlinear: no further constraints.
  \end{enumerate}
\item
  \begin{enumerate}
  \item Unconstrained: Optimal solution searched in full \(\RR^n\). Easier to characterize, and
    usually to solve.
  \item Constrained: Optimal solution in an admissible region, usually more difficult to
    setup/characterize.
  \end{enumerate}
\end{enumerate}

\paragraph{Convexity.}
A set \(X\) is convex, if for all \(x, y \in X\) and \(\alpha \in [0,1]\):
\begin{equation*}
  \alpha x + (1 - \alpha) y \in X.
\end{equation*}
This means that \(X\) contains all convex combinations of points from it.

\paragraph{Convex Functions.}
If \(X\) is a convex set, then \(f: \RR \to \RR\) is called convex if for all \(x, y \in X\) and
\(\alpha \in [0,1]\):
\begin{equation*}
  f(\alpha x + (1 - \alpha) y) \leq \alpha f(x) + (1 - \alpha) f(y).
\end{equation*}
This means that no points lie below any tangent.

\paragraph{Level Sets.}
For an objective function \(f: X \to \RR\), and \(c \in \RR\), the sets
\begin{equation*}
  S_c(f) = \{x \in X: f(x) = c\}
\end{equation*}
are called \emph{level sets} of \(f\). They can be convex even if \(f\) is not!

\paragraph{Definiteness.}
A matrix \(Q\) is called \emph{positive semidefinite} if \(\T{x} Q x \geq 0\) for all \(x\).  \(Q\)
is called \emph{positive definite} if \(\T{x} Q x > 0\) for all \(x \neq 0\).  Sometimes this is
written as \(Q \succeq 0\) and \(Q \succ 0\).

\paragraph{Local and Global Minima.}
A point \(x^*\) is called an \emph{unconstrained global minimum} of \(f\) if for all \(x\)
\begin{equation*}
  f(x^*) \leq f(x).
\end{equation*}
\(x^*\) is called an \emph{unconstrained local minimum} of \(f\) if it is minimal in some
neighbourhood; i.e., there is an \(\epsilon > 0\) such that
\begin{equation*}
  f(x^*) \leq f(x) \quad \forall x \text{ with } \lVert x^* - x \rVert \leq \epsilon.
\end{equation*}
For \emph{constrained} minima, we just require additionally that \(x \in X \subset \RR^n\).

\paragraph{First Order Neccessary Condition for Optimality.}
In a small neighbourhood of \(x^*\), we can by Taylor expansion write \(f\) as
\begin{equation*}
  f(x) = f(x^* + \Delta x) = f(x^*) + \T{\nabla f(x^*)} \Delta x + o(\lVert \Delta x \rVert).
\end{equation*}
Since \(x^*\) is a local minimum, \(f(x^* + \Delta x) - f(x^*) \geq 0\), and we have
\begin{equation*}
  f(x^*) + \T{\nabla f(x^*)} \Delta x - f(x^*) = \T{\nabla f(x^*)} \Delta x \geq 0.
\end{equation*}
Since wlog. we can choose \(\Delta x\) to have the opposite sign, it holds also that
\begin{equation*}
  \T{\nabla f(x^*)} \Delta x \leq 0,
\end{equation*}
so \(\T{\nabla f(x^*)} \Delta x = 0\), which, since \(\Delta x\) is arbitrary, implies that
\(\nabla f(x^*) = 0\).

\paragraph{Second Order Neccessary Condition for Optimality.}
By second order Taylor expansion, we get
\begin{align*}
  0 &\leq f(x^* + \Delta x) - f(x^*) \\
    &= f(x^*) + \underbrace{\T{\nabla f(x^*)} \Delta x}_{= 0} +
      \frac{1}{2} \T{\Delta x} \nabla^2 f(x^*) \Delta x + o(\lVert \Delta x \rVert^2) - f(x^*) \\
    &=  \frac{1}{2} \T{\Delta x} \nabla^2 f(x^*) \Delta x + o(\lVert \Delta x \rVert^2).
\end{align*}
From this follows that \(\T{\Delta x} \nabla^2 f(x^*) \Delta x \geq 0\).  Since \(\Delta x\) is
arbitrary, this means that \(\nabla^2 f(x^*)\) must be positive semidefinite.

\paragraph{Sufficient Condition for Optimality.}
If for a point \(x^*\) we have \(\T{\nabla f(x^*)} = 0\) and \(\nabla^2 f(x^*)\) positive
\emph{definite} (no ``semi-''!), then \(x^*\) is a strict unconstrained local minimum of
f. 

\paragraph{Minima of Convex Functions.}
For a convex function \(f\), local minima are also global minima: suppose \(x*\) were a local, but
not global minimum. Then there must be some \(y^* \neq x^*\) with \(f(y^*) < f(x^*)\).  By
convexity, we have for all \(\alpha \in [0, 1)\):
\begin{equation*}
  f(\alpha x^* + (1 - \alpha) y^*) < \alpha f(x^*) + (1 - \alpha) f(y^*) < f(x^*),
\end{equation*}
which contradicts the assumption, so \(x^*\) must also be a global minimum.

Furthermore, the neccessary condition for minima, \(\nabla f(x^*) = 0\), for convex functions
becomes a sufficient condition.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gradient Methods}

\paragraph{Basic Idea.}
To find a minimum of \(f\), we construct a sequence \(\kth{x}\) such that for all \(k\),
\(f(\kth[k+1]{x}) < f(\kth{x})\).  To do that, we choose an initial \(\kth[0]{x}\) and then set
\begin{equation*}
  \kth[k+1]{x} = \kth{x} + \kth{\alpha} \kth{d}.
\end{equation*}
Here \(\kth{\alpha}\) is some step size, and \(\kth{d}\) is a \emph{descent direction} which must
satisfy
\begin{equation*}
  \pd{f}{{\kth{d}}}(\kth{x}) = \T{\nabla f(\kth{x})} \kth{d} < 0, 
\end{equation*}
where \(\pd{f}{{\kth{d}}}\) is the directional derivative in direction \(\kth{d}\).

\paragraph{Matrix-Scaled Gradients.}
Given the above form, one can choose \(\kth{d} = -\kth{D} \nabla f(\kth{x})\) for a positive
definite \(\kth{D}\):
\begin{equation*}
  \T{\nabla f(\kth{x})} \kth{d} = -\T{\nabla f(\kth{x})} \kth{D} \nabla f(\kth{x}) < 0,
\end{equation*}
by the definition of positive definiteness.

\paragraph{Steepest descent.} \(\kth{D} = I\). Simple, but slow convergence.

\paragraph{Newton's method.} \(\kth{D} = (\nabla^2 f(\kth{x}))^{-1}\).  Fast convergence, but
\(\nabla^2 f(\kth{x})\) needs to be positive definite to be invertible.  Corresponds to local
approximation by a quadratic surface (see below).
  
\paragraph{Levenberg-Marquart method.} \(\kth{D} = (\nabla^2 f(\kth{x}) + \lambda ()^{-1}\).  Tries
to fix problems with Newton's method by regularization.

\paragraph{Diagonal scaling.} \(\kth{D} = \diag(\kth{d}_1, \ldots, \kth{d}_n)\). E.g. approximating
Newton's method with
\begin{equation*}
  \kth{d}_i = \left( \pd[2]{f}{x_i}(\kth{x}) \right)^{-1}.
\end{equation*}

\paragraph{Gauss-Newton method.} For a nonlinear least-squares problem
\(f(x) = \frac{1}{2} \lVert g(x) \rVert^2\), we can choose
\(\kth{D} = \left( \nabla g(\kth{x} \T{\nabla g(\kth{x})} \right)^{-1}\).  This is related to the
pseudo-inverse.

\end{document}
